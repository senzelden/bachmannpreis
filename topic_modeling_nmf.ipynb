{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508.txt has 4624 words.\n",
      "509.txt has 3983 words.\n",
      "510.txt has 2762 words.\n",
      "511.txt has 4026 words.\n",
      "512.txt has 4775 words.\n",
      "513.txt has 4122 words.\n",
      "514.txt has 4295 words.\n",
      "515.txt has 4106 words.\n",
      "516.txt has 4066 words.\n",
      "517.txt has 3250 words.\n",
      "518.txt has 4968 words.\n",
      "519.txt has 4564 words.\n",
      "520.txt has 3478 words.\n",
      "521.txt has 4213 words.\n",
      "522.txt has 4460 words.\n",
      "523.txt has 3728 words.\n",
      "524.txt has 4209 words.\n",
      "525.txt has 5308 words.\n",
      "526.txt has 3873 words.\n",
      "527.txt has 5079 words.\n",
      "528.txt has 3746 words.\n",
      "529.txt has 3740 words.\n",
      "530.txt has 4056 words.\n",
      "531.txt has 3703 words.\n",
      "532.txt has 5645 words.\n",
      "533.txt has 3192 words.\n",
      "534.txt has 4066 words.\n",
      "535.txt has 3511 words.\n",
      "536.txt has 4452 words.\n",
      "537.txt has 4303 words.\n",
      "538.txt has 4275 words.\n",
      "539.txt has 3244 words.\n",
      "540.txt has 3538 words.\n",
      "541.txt has 4195 words.\n",
      "542.txt has 4570 words.\n",
      "543.txt has 4269 words.\n",
      "544.txt has 2479 words.\n",
      "545.txt has 3825 words.\n",
      "546.txt has 4257 words.\n",
      "547.txt has 4441 words.\n",
      "548.txt has 4367 words.\n",
      "550.txt has 4635 words.\n",
      "551.txt has 3157 words.\n",
      "552.txt has 4330 words.\n",
      "553.txt has 4634 words.\n",
      "554.txt has 3671 words.\n",
      "555.txt has 2383 words.\n",
      "556.txt has 2403 words.\n",
      "557.txt has 3992 words.\n",
      "558.txt has 3549 words.\n",
      "559.txt has 3489 words.\n",
      "560.txt has 3824 words.\n",
      "561.txt has 3761 words.\n",
      "562.txt has 4196 words.\n",
      "563.txt has 3409 words.\n",
      "564.txt has 3964 words.\n",
      "565.txt has 4001 words.\n",
      "566.txt has 3452 words.\n",
      "567.txt has 3801 words.\n",
      "568.txt has 3576 words.\n",
      "569.txt has 2364 words.\n",
      "570.txt has 3723 words.\n",
      "571.txt has 4266 words.\n",
      "572.txt has 2148 words.\n",
      "573.txt has 4873 words.\n",
      "574.txt has 3569 words.\n",
      "575.txt has 3426 words.\n",
      "576.txt has 3460 words.\n",
      "577.txt has 3317 words.\n",
      "578.txt has 3263 words.\n",
      "579.txt has 3628 words.\n",
      "580.txt has 4005 words.\n",
      "581.txt has 4261 words.\n",
      "582.txt has 4933 words.\n",
      "583.txt has 3725 words.\n",
      "584.txt has 3910 words.\n",
      "585.txt has 4724 words.\n",
      "586.txt has 4978 words.\n",
      "587.txt has 4139 words.\n",
      "588.txt has 4028 words.\n",
      "589.txt has 1964 words.\n",
      "590.txt has 4517 words.\n",
      "591.txt has 3797 words.\n",
      "592.txt has 4038 words.\n",
      "593.txt has 3321 words.\n",
      "594.txt has 5027 words.\n",
      "595.txt has 3723 words.\n",
      "596.txt has 3965 words.\n",
      "597.txt has 4033 words.\n",
      "598.txt has 4356 words.\n",
      "599.txt has 3883 words.\n",
      "600.txt has 3176 words.\n",
      "601.txt has 3956 words.\n",
      "602.txt has 4367 words.\n",
      "603.txt has 4498 words.\n",
      "604.txt has 4597 words.\n",
      "605.txt has 3454 words.\n",
      "606.txt has 5098 words.\n",
      "607.txt has 4263 words.\n",
      "608.txt has 3870 words.\n",
      "609.txt has 3533 words.\n",
      "610.txt has 5013 words.\n",
      "611.txt has 3539 words.\n",
      "612.txt has 3119 words.\n",
      "613.txt has 2761 words.\n",
      "614.txt has 3100 words.\n",
      "615.txt has 4793 words.\n",
      "616.txt has 4149 words.\n",
      "617.txt has 3512 words.\n",
      "618.txt has 4612 words.\n",
      "619.txt has 4769 words.\n",
      "620.txt has 4636 words.\n",
      "621.txt has 4054 words.\n",
      "622.txt has 5092 words.\n",
      "623.txt has 4832 words.\n",
      "624.txt has 3845 words.\n",
      "625.txt has 4269 words.\n",
      "626.txt has 3665 words.\n",
      "627.txt has 3727 words.\n",
      "628.txt has 4817 words.\n",
      "629.txt has 4095 words.\n",
      "630.txt has 4460 words.\n",
      "631.txt has 4614 words.\n",
      "632.txt has 4588 words.\n",
      "633.txt has 4153 words.\n",
      "634.txt has 5457 words.\n",
      "635.txt has 3605 words.\n",
      "636.txt has 4801 words.\n",
      "637.txt has 3841 words.\n",
      "638.txt has 4175 words.\n",
      "639.txt has 4586 words.\n",
      "640.txt has 3886 words.\n",
      "641.txt has 3611 words.\n",
      "642.txt has 4301 words.\n",
      "643.txt has 4494 words.\n",
      "644.txt has 3793 words.\n",
      "645.txt has 4637 words.\n",
      "646.txt has 4158 words.\n",
      "647.txt has 3797 words.\n",
      "648.txt has 3682 words.\n",
      "649.txt has 3331 words.\n",
      "650.txt has 5622 words.\n",
      "651.txt has 3020 words.\n",
      "652.txt has 3746 words.\n",
      "653.txt has 4099 words.\n",
      "654.txt has 4133 words.\n",
      "655.txt has 3746 words.\n",
      "656.txt has 5645 words.\n",
      "657.txt has 4561 words.\n",
      "658.txt has 4703 words.\n",
      "659.txt has 4153 words.\n",
      "660.txt has 4133 words.\n",
      "661.txt has 3282 words.\n",
      "662.txt has 5671 words.\n",
      "663.txt has 2924 words.\n",
      "664.txt has 4463 words.\n",
      "665.txt has 4244 words.\n",
      "666.txt has 3908 words.\n",
      "667.txt has 3481 words.\n",
      "668.txt has 3905 words.\n",
      "669.txt has 3503 words.\n",
      "670.txt has 4060 words.\n",
      "671.txt has 3964 words.\n",
      "672.txt has 4968 words.\n",
      "673.txt has 3952 words.\n",
      "674.txt has 4059 words.\n",
      "675.txt has 3248 words.\n",
      "676.txt has 3130 words.\n",
      "677.txt has 3245 words.\n",
      "678.txt has 4419 words.\n",
      "679.txt has 2998 words.\n",
      "680.txt has 3399 words.\n",
      "681.txt has 3760 words.\n",
      "682.txt has 3511 words.\n",
      "683.txt has 3734 words.\n",
      "684.txt has 4265 words.\n",
      "685.txt has 4003 words.\n",
      "686.txt has 3700 words.\n",
      "687.txt has 5292 words.\n",
      "688.txt has 3849 words.\n",
      "689.txt has 4358 words.\n",
      "690.txt has 5155 words.\n",
      "691.txt has 4026 words.\n",
      "692.txt has 3399 words.\n",
      "693.txt has 4635 words.\n",
      "694.txt has 4503 words.\n",
      "695.txt has 3672 words.\n",
      "696.txt has 4325 words.\n",
      "697.txt has 3586 words.\n",
      "698.txt has 3713 words.\n",
      "699.txt has 2536 words.\n",
      "700.txt has 3692 words.\n",
      "701.txt has 4117 words.\n",
      "702.txt has 3517 words.\n",
      "703.txt has 4165 words.\n",
      "704.txt has 4408 words.\n",
      "705.txt has 4030 words.\n",
      "706.txt has 4747 words.\n",
      "707.txt has 2809 words.\n",
      "708.txt has 3680 words.\n",
      "709.txt has 3755 words.\n",
      "710.txt has 4174 words.\n",
      "711.txt has 4621 words.\n",
      "712.txt has 4709 words.\n",
      "713.txt has 3758 words.\n",
      "714.txt has 3548 words.\n",
      "715.txt has 3425 words.\n",
      "716.txt has 4062 words.\n",
      "717.txt has 3512 words.\n",
      "718.txt has 4551 words.\n",
      "719.txt has 2402 words.\n",
      "720.txt has 3275 words.\n",
      "721.txt has 3146 words.\n",
      "722.txt has 3504 words.\n",
      "723.txt has 3067 words.\n",
      "724.txt has 2983 words.\n",
      "725.txt has 3237 words.\n",
      "726.txt has 3115 words.\n",
      "727.txt has 3651 words.\n",
      "728.txt has 3208 words.\n",
      "729.txt has 3314 words.\n",
      "730.txt has 3462 words.\n",
      "731.txt has 2475 words.\n",
      "732.txt has 3347 words.\n",
      "733.txt has 3751 words.\n",
      "734.txt has 3022 words.\n",
      "735.txt has 3322 words.\n",
      "736.txt has 3538 words.\n",
      "737.txt has 3616 words.\n",
      "738.txt has 3257 words.\n",
      "739.txt has 3877 words.\n",
      "740.txt has 3101 words.\n",
      "741.txt has 4581 words.\n",
      "742.txt has 3990 words.\n",
      "743.txt has 4393 words.\n",
      "744.txt has 3254 words.\n",
      "745.txt has 3794 words.\n",
      "746.txt has 4828 words.\n",
      "747.txt has 2776 words.\n",
      "748.txt has 3103 words.\n",
      "749.txt has 1667 words.\n",
      "750.txt has 4065 words.\n",
      "751.txt has 3333 words.\n",
      "752.txt has 4146 words.\n",
      "753.txt has 4565 words.\n",
      "754.txt has 3600 words.\n",
      "755.txt has 3097 words.\n",
      "756.txt has 4037 words.\n",
      "757.txt has 3509 words.\n",
      "758.txt has 3804 words.\n",
      "759.txt has 4097 words.\n",
      "760.txt has 3746 words.\n",
      "761.txt has 2701 words.\n",
      "762.txt has 3300 words.\n",
      "763.txt has 3800 words.\n",
      "764.txt has 3219 words.\n",
      "765.txt has 3203 words.\n",
      "766.txt has 4412 words.\n",
      "767.txt has 2711 words.\n",
      "768.txt has 3868 words.\n",
      "769.txt has 5017 words.\n",
      "770.txt has 4117 words.\n",
      "771.txt has 3861 words.\n",
      "772.txt has 2743 words.\n",
      "773.txt has 4173 words.\n",
      "774.txt has 3076 words.\n",
      "775.txt has 3512 words.\n",
      "776.txt has 3331 words.\n",
      "777.txt has 1929 words.\n",
      "778.txt has 3466 words.\n",
      "779.txt has 2973 words.\n",
      "780.txt has 4301 words.\n",
      "781.txt has 3031 words.\n",
      "782.txt has 2807 words.\n",
      "783.txt has 3200 words.\n",
      "784.txt has 3794 words.\n",
      "785.txt has 3498 words.\n",
      "786.txt has 2751 words.\n",
      "787.txt has 3728 words.\n",
      "788.txt has 3253 words.\n",
      "789.txt has 3560 words.\n",
      "790.txt has 3763 words.\n",
      "791.txt has 3691 words.\n",
      "792.txt has 3350 words.\n",
      "793.txt has 4019 words.\n",
      "794.txt has 2716 words.\n",
      "795.txt has 3446 words.\n",
      "796.txt has 2511 words.\n",
      "797.txt has 3312 words.\n",
      "798.txt has 1958 words.\n",
      "799.txt has 2860 words.\n",
      "800.txt has 3266 words.\n",
      "801.txt has 3674 words.\n",
      "802.txt has 2751 words.\n",
      "803.txt has 3561 words.\n",
      "804.txt has 3491 words.\n",
      "805.txt has 3563 words.\n",
      "806.txt has 2830 words.\n",
      "807.txt has 2324 words.\n",
      "808.txt has 2829 words.\n",
      "809.txt has 3803 words.\n",
      "810.txt has 3536 words.\n",
      "811.txt has 3351 words.\n",
      "812.txt has 2769 words.\n",
      "813.txt has 3683 words.\n",
      "814.txt has 3015 words.\n",
      "815.txt has 2926 words.\n",
      "816.txt has 3327 words.\n",
      "817.txt has 2419 words.\n",
      "818.txt has 2861 words.\n",
      "819.txt has 3527 words.\n",
      "820.txt has 3932 words.\n",
      "821.txt has 4634 words.\n",
      "822.txt has 3462 words.\n",
      "823.txt has 2794 words.\n",
      "824.txt has 3602 words.\n",
      "825.txt has 3835 words.\n",
      "826.txt has 3740 words.\n",
      "827.txt has 3656 words.\n",
      "828.txt has 3927 words.\n",
      "829.txt has 3206 words.\n",
      "830.txt has 3800 words.\n",
      "831.txt has 2753 words.\n",
      "832.txt has 2238 words.\n",
      "833.txt has 3274 words.\n",
      "834.txt has 3539 words.\n",
      "835.txt has 3850 words.\n",
      "836.txt has 2749 words.\n",
      "837.txt has 4343 words.\n",
      "838.txt has 3509 words.\n",
      "839.txt has 3755 words.\n",
      "840.txt has 3532 words.\n",
      "841.txt has 3370 words.\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "indices = []\n",
    "for i in range(508, 842):\n",
    "    if f\"{i}.txt\" in os.listdir(\"Texte/cleaned\"):\n",
    "        with open(f\"Texte/cleaned/{i}.txt\", \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "            texts.append(text)\n",
    "            words = text.split()\n",
    "            print(f\"{i}.txt has {len(words)} words.\")\n",
    "            indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_spacy(short_story, model):\n",
    "    cleaned_story = \"\"\n",
    "    doc = model(short_story)\n",
    "    for word in doc:\n",
    "        if not word.is_stop and word.is_alpha:\n",
    "            cleaned_story += word.lemma_ + \" \"\n",
    "    return cleaned_story.strip()\n",
    "\n",
    "\n",
    "def create_texts_corpus(texts):\n",
    "    \"\"\"loads song texts from files and stores lyrics and artist index in seperate lists\"\"\"\n",
    "    cleaned_texts = []\n",
    "    for i, text in enumerate(texts):\n",
    "        cleaned_texts.append(preprocess_text_with_spacy(text, lang_model))\n",
    "        print(i + 508)\n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2c1c63b2293f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_texts_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-11dd9a3707f6>\u001b[0m in \u001b[0;36mcreate_texts_corpus\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcleaned_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcleaned_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text_with_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m508\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-11dd9a3707f6>\u001b[0m in \u001b[0;36mpreprocess_text_with_spacy\u001b[0;34m(short_story, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text_with_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_story\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcleaned_story\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_story\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Coding/spiced/venv/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpipes.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.pipes.Tagger.set_annotations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.assign_tag_id\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmorphology.pyx\u001b[0m in \u001b[0;36mspacy.morphology.Morphology.lemmatize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Coding/spiced/venv/lib/python3.8/site-packages/spacy/lemmatizer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string, univ_pos, morphology)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mlookup_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lemma_lookup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"lemma_rules\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlookup_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cleaned_texts = create_texts_corpus(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"index\": indices, \"cleaned_text\": cleaned_texts})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german = [\"a\",\"ab\",\"aber\",\"ach\",\"acht\",\"achte\",\"achten\",\"achter\",\"achtes\",\"ag\",\"alle\",\"allein\",\"allem\",\"allen\",\"aller\",\"allerdings\",\"alles\",\"allgemeinen\",\"als\",\"also\",\"am\",\"an\",\"ander\",\"andere\",\"anderem\",\"anderen\",\"anderer\",\"anderes\",\"anderm\",\"andern\",\"anderr\",\"anders\",\"au\",\"auch\",\"auf\",\"aus\",\"ausser\",\"ausserdem\",\"außer\",\"außerdem\",\"b\",\"bald\",\"bei\",\"beide\",\"beiden\",\"beim\",\"beispiel\",\"bekannt\",\"bereits\",\"besonders\",\"besser\",\"besten\",\"bin\",\"bis\",\"bisher\",\"bist\",\"c\",\"d\",\"d.h\",\"da\",\"dabei\",\"dadurch\",\"dafür\",\"dagegen\",\"daher\",\"dahin\",\"dahinter\",\"damals\",\"damit\",\"danach\",\"daneben\",\"dank\",\"dann\",\"daran\",\"darauf\",\"daraus\",\"darf\",\"darfst\",\"darin\",\"darum\",\"darunter\",\"darüber\",\"das\",\"dasein\",\"daselbst\",\"dass\",\"dasselbe\",\"davon\",\"davor\",\"dazu\",\"dazwischen\",\"daß\",\"dein\",\"deine\",\"deinem\",\"deinen\",\"deiner\",\"deines\",\"dem\",\"dementsprechend\",\"demgegenüber\",\"demgemäss\",\"demgemäß\",\"demselben\",\"demzufolge\",\"den\",\"denen\",\"denn\",\"denselben\",\"der\",\"deren\",\"derer\",\"derjenige\",\"derjenigen\",\"dermassen\",\"dermaßen\",\"derselbe\",\"derselben\",\"des\",\"deshalb\",\"desselben\",\"dessen\",\"deswegen\",\"dich\",\"die\",\"diejenige\",\"diejenigen\",\"dies\",\"diese\",\"dieselbe\",\"dieselben\",\"diesem\",\"diesen\",\"dieser\",\"dieses\",\"dir\",\"doch\",\"dort\",\"drei\",\"drin\",\"dritte\",\"dritten\",\"dritter\",\"drittes\",\"du\",\"durch\",\"durchaus\",\"durfte\",\"durften\",\"dürfen\",\"dürft\",\"e\",\"eben\",\"ebenso\",\"ehrlich\",\"ei\",\"ei,\",\"eigen\",\"eigene\",\"eigenen\",\"eigener\",\"eigenes\",\"ein\",\"einander\",\"eine\",\"einem\",\"einen\",\"einer\",\"eines\",\"einig\",\"einige\",\"einigem\",\"einigen\",\"einiger\",\"einiges\",\"einmal\",\"eins\",\"elf\",\"en\",\"ende\",\"endlich\",\"entweder\",\"er\",\"ernst\",\"erst\",\"erste\",\"ersten\",\"erster\",\"erstes\",\"es\",\"etwa\",\"etwas\",\"euch\",\"euer\",\"eure\",\"eurem\",\"euren\",\"eurer\",\"eures\",\"f\",\"folgende\",\"früher\",\"fünf\",\"fünfte\",\"fünften\",\"fünfter\",\"fünftes\",\"für\",\"g\",\"gab\",\"ganz\",\"ganze\",\"ganzen\",\"ganzer\",\"ganzes\",\"gar\",\"gedurft\",\"gegen\",\"gegenüber\",\"gehabt\",\"gehen\",\"geht\",\"gekannt\",\"gekonnt\",\"gemacht\",\"gemocht\",\"gemusst\",\"genug\",\"gerade\",\"gern\",\"gesagt\",\"geschweige\",\"gewesen\",\"gewollt\",\"geworden\",\"gibt\",\"ging\",\"gleich\",\"gott\",\"gross\",\"grosse\",\"grossen\",\"grosser\",\"grosses\",\"groß\",\"große\",\"großen\",\"großer\",\"großes\",\"gut\",\"gute\",\"guter\",\"gutes\",\"h\",\"hab\",\"habe\",\"haben\",\"habt\",\"hast\",\"hat\",\"hatte\",\"hatten\",\"hattest\",\"hattet\",\"heisst\",\"her\",\"heute\",\"hier\",\"hin\",\"hinter\",\"hoch\",\"hätte\",\"hätten\",\"i\",\"ich\",\"ihm\",\"ihn\",\"ihnen\",\"ihr\",\"ihre\",\"ihrem\",\"ihren\",\"ihrer\",\"ihres\",\"im\",\"immer\",\"in\",\"indem\",\"infolgedessen\",\"ins\",\"irgend\",\"ist\",\"j\",\"ja\",\"jahr\",\"jahre\",\"jahren\",\"je\",\"jede\",\"jedem\",\"jeden\",\"jeder\",\"jedermann\",\"jedermanns\",\"jedes\",\"jedoch\",\"jemand\",\"jemandem\",\"jemanden\",\"jene\",\"jenem\",\"jenen\",\"jener\",\"jenes\",\"jetzt\",\"k\",\"kam\",\"kann\",\"kannst\",\"kaum\",\"kein\",\"keine\",\"keinem\",\"keinen\",\"keiner\",\"keines\",\"kleine\",\"kleinen\",\"kleiner\",\"kleines\",\"kommen\",\"kommt\",\"konnte\",\"konnten\",\"kurz\",\"können\",\"könnt\",\"könnte\",\"l\",\"lang\",\"lange\",\"leicht\",\"leide\",\"lieber\",\"los\",\"m\",\"machen\",\"macht\",\"machte\",\"mag\",\"magst\",\"mahn\",\"mal\",\"man\",\"manche\",\"manchem\",\"manchen\",\"mancher\",\"manches\",\"mann\",\"mehr\",\"mein\",\"meine\",\"meinem\",\"meinen\",\"meiner\",\"meines\",\"mensch\",\"menschen\",\"mich\",\"mir\",\"mit\",\"mittel\",\"mochte\",\"mochten\",\"morgen\",\"muss\",\"musst\",\"musste\",\"mussten\",\"muß\",\"mußt\",\"möchte\",\"mögen\",\"möglich\",\"mögt\",\"müssen\",\"müsst\",\"müßt\",\"n\",\"na\",\"nach\",\"nachdem\",\"nahm\",\"natürlich\",\"neben\",\"nein\",\"neue\",\"neuen\",\"neun\",\"neunte\",\"neunten\",\"neunter\",\"neuntes\",\"nicht\",\"nichts\",\"nie\",\"niemand\",\"niemandem\",\"niemanden\",\"noch\",\"nun\",\"nur\",\"o\",\"ob\",\"oben\",\"oder\",\"offen\",\"oft\",\"ohne\",\"ordnung\",\"p\",\"q\",\"r\",\"recht\",\"rechte\",\"rechten\",\"rechter\",\"rechtes\",\"richtig\",\"rund\",\"s\",\"sa\",\"sache\",\"sagt\",\"sagte\",\"sah\",\"satt\",\"schlecht\",\"schluss\",\"schon\",\"sechs\",\"sechste\",\"sechsten\",\"sechster\",\"sechstes\",\"sehr\",\"sei\",\"seid\",\"seien\",\"sein\",\"seine\",\"seinem\",\"seinen\",\"seiner\",\"seines\",\"seit\",\"seitdem\",\"selbst\",\"sich\",\"sie\",\"sieben\",\"siebente\",\"siebenten\",\"siebenter\",\"siebentes\",\"sind\",\"so\",\"solang\",\"solche\",\"solchem\",\"solchen\",\"solcher\",\"solches\",\"soll\",\"sollen\",\"sollst\",\"sollt\",\"sollte\",\"sollten\",\"sondern\",\"sonst\",\"soweit\",\"sowie\",\"später\",\"startseite\",\"statt\",\"steht\",\"suche\",\"t\",\"tag\",\"tage\",\"tagen\",\"tat\",\"teil\",\"tel\",\"tritt\",\"trotzdem\",\"tun\",\"u\",\"uhr\",\"um\",\"und\",\"uns\",\"unse\",\"unsem\",\"unsen\",\"unser\",\"unsere\",\"unserer\",\"unses\",\"unter\",\"v\",\"vergangenen\",\"viel\",\"viele\",\"vielem\",\"vielen\",\"vielleicht\",\"vier\",\"vierte\",\"vierten\",\"vierter\",\"viertes\",\"vom\",\"von\",\"vor\",\"w\",\"wahr\",\"wann\",\"war\",\"waren\",\"warst\",\"wart\",\"warum\",\"was\",\"weg\",\"wegen\",\"weil\",\"weit\",\"weiter\",\"weitere\",\"weiteren\",\"weiteres\",\"welche\",\"welchem\",\"welchen\",\"welcher\",\"welches\",\"wem\",\"wen\",\"wenig\",\"wenige\",\"weniger\",\"weniges\",\"wenigstens\",\"wenn\",\"wer\",\"werde\",\"werden\",\"werdet\",\"weshalb\",\"wessen\",\"wie\",\"wieder\",\"wieso\",\"will\",\"willst\",\"wir\",\"wird\",\"wirklich\",\"wirst\",\"wissen\",\"wo\",\"woher\",\"wohin\",\"wohl\",\"wollen\",\"wollt\",\"wollte\",\"wollten\",\"worden\",\"wurde\",\"wurden\",\"während\",\"währenddem\",\"währenddessen\",\"wäre\",\"würde\",\"würden\",\"x\",\"y\",\"z\",\"z.b\",\"zehn\",\"zehnte\",\"zehnten\",\"zehnter\",\"zehntes\",\"zeit\",\"zu\",\"zuerst\",\"zugleich\",\"zum\",\"zunächst\",\"zur\",\"zurück\",\"zusammen\",\"zwanzig\",\"zwar\",\"zwei\",\"zweite\",\"zweiten\",\"zweiter\",\"zweites\",\"zwischen\",\"zwölf\",\"über\",\"überhaupt\",\"übrigens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"philipp\",\n",
    "    \"fritz\",\n",
    "    \"alfred\",\n",
    "    \"birkhahn\",\n",
    "    \"leander\",\n",
    "    \"tanja\",\n",
    "    \"carlo\",\n",
    "    \"evi\",\n",
    "    \"sartorius\",\n",
    "    \"uwe\",\n",
    "    \"walter\",\n",
    "    \"irmi\",\n",
    "    \"ada\",\n",
    "    \"nele\",\n",
    "    \"neles\",\n",
    "    \"jo\",\n",
    "    \"timo\",\n",
    "    \"anne\",\n",
    "    \"lucia\",\n",
    "    \"lydia\",\n",
    "    \"hermann\",\n",
    "    \"alexander\",\n",
    "    \"gustav\",\n",
    "    \"nina\",\n",
    "    \"joe\",\n",
    "    \"san\",\n",
    "    \"schulze\",\n",
    "    \"berti\",\n",
    "    \"anton\",\n",
    "    \"manuel\",\n",
    "    \"barbara\",\n",
    "    \"dirk\",\n",
    "    \"zoran\",\n",
    "    \"faruk\",\n",
    "    \"lothar\",\n",
    "    \"ibrahim\",\n",
    "    \"helmut\",\n",
    "    \"ine\",\n",
    "    \"johanna\",\n",
    "    \"joseph\",\n",
    "    \"oliver\",\n",
    "    \"kara\",\n",
    "    \"jakob\",\n",
    "    \"charlotte\",\n",
    "    \"tobias\",\n",
    "    \"nora\",\n",
    "    \"harald\",\n",
    "    \"felix\",\n",
    "    \"bert\",\n",
    "    \"matthias\",\n",
    "    \"lukas\",\n",
    "    \"robert\",\n",
    "    \"luise\",\n",
    "    \"julie\",\n",
    "    \"max\",\n",
    "    \"leo\",\n",
    "    \"katja\",\n",
    "    \"theo\",\n",
    "    \"maria\",\n",
    "    \"robert\",\n",
    "    \"jule\",\n",
    "    \"adam\",\n",
    "    \"erika\",\n",
    "    \"eva\",\n",
    "    \"stefan\",\n",
    "    \"moritz\",\n",
    "    \"anita\",\n",
    "    \"carla\",\n",
    "    \"till\",\n",
    "    \"marko\",\n",
    "    \"julia\",\n",
    "    \"ruth\",\n",
    "    \"irene\",\n",
    "    \"wolfgang\",\n",
    "    \"fred\",\n",
    "    \"silke\",\n",
    "    \"albert\",\n",
    "    \"alma\",\n",
    "    \"silke\",\n",
    "    \"gertrud\",\n",
    "    \"jürgen\",\n",
    "    \"judith\",\n",
    "    \"sascha\",\n",
    "    \"anna\",\n",
    "    \"emma\",\n",
    "    \"guido\",\n",
    "    \"maria\",\n",
    "    \"oskar\",\n",
    "    \"simone\",\n",
    "    \"gerda\",\n",
    "    \"patrick\",\n",
    "    \"jan\",\n",
    "    \"emily\",\n",
    "    \"paul\",\n",
    "    \"lisa\",\n",
    "    \"viktor\",\n",
    "]\n",
    "\n",
    "\n",
    "response = requests.get(\"https://www.vorname.com/beliebte_vornamen,0.html\")\n",
    "page = soup(response.text, \"html.parser\")\n",
    "\n",
    "common_names = []\n",
    "for name_box in page.find_all(attrs={\"class\": \"name_box\"}):\n",
    "    common_names.append(name_box.find(\"a\").text.lower())\n",
    "\n",
    "stop_names = set(names + common_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "new_stop_words = german + list(stop_names)\n",
    "new_stop_words.sort()\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.8, min_df=2, stop_words=new_stop_words)\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words=new_stop_words)\n",
    "doc_term_matrix = tfidf_vect.fit_transform(df['cleaned_text'].values.astype('U'))\n",
    "count_vect_matrix = count_vect.fit_transform(df['cleaned_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "\n",
    "tfidf_matrix = pd.DataFrame.sparse.from_spmatrix(count_vect_matrix)\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_matrix = pd.DataFrame.sparse.from_spmatrix(count_vect_matrix)\n",
    "cv_matrix.columns = count_vect.get_feature_names()\n",
    "cv_matrix.index = indices\n",
    "# cv_matrix.to_csv(\"count_vectors_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_matrix.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dfs = []\n",
    "text_id = 600\n",
    "for text_id in cv_matrix.index:\n",
    "    temp_series = cv_matrix.loc[text_id].sort_values(ascending=False)[:20]\n",
    "    temp_df = pd.DataFrame(temp_series)\n",
    "    temp_df['text_id'] = [text_id] * len(temp_series)\n",
    "    final_format = temp_df.reset_index().set_index('text_id').rename(columns={\"index\": \"word\", text_id: \"word_count\"})\n",
    "    temp_dfs.append(final_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_series = cv_matrix.sum().sort_values(ascending=False)[:20]\n",
    "temp_df = pd.DataFrame(temp_series)\n",
    "temp_df['text_id'] = [-999] * len(temp_series)\n",
    "final_format = temp_df.reset_index().set_index('text_id').rename(columns={\"index\": \"word\", 0: \"word_count\"})\n",
    "temp_dfs.append(final_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = pd.concat(temp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_common_words.to_csv(\"most_common_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cv_matrix.sum().sort_values(ascending=False).to_csv(\"most_common_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_count_words = pd.DataFrame(cv_matrix.apply(lambda x:list(cv_matrix.columns[np.array(x).argsort()[::-1][:100]]), axis=1).to_list(),  columns=list(range(1,101)))\n",
    "highest_count_words.index = indices\n",
    "highest_count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.columns = tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "most_relevant_words = pd.DataFrame(tfidf_matrix.apply(lambda x:list(tfidf_matrix.columns[np.array(x).argsort()[::-1][:100]]), axis=1).to_list(),  columns=list(range(1,101)))\n",
    "most_relevant_words.index = indices\n",
    "# most_relevant_words.to_csv(\"tfidf_most_relevant_words.csv\")\n",
    "most_relevant_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe try out LDA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "nmf = NMF(n_components=15, random_state=42)\n",
    "nmf.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = nmf.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_topic_words:\n",
    "    print(tfidf_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_words_list = []\n",
    "for i,topic in enumerate(nmf.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    top_10_words = [tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]]\n",
    "    print(top_10_words)\n",
    "    top_10_words_list.append(\"|\".join(top_10_words))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topic_words = []\n",
    "for num in topic_values.argmax(axis=1):\n",
    "    top_topic_words.append(top_10_words_list[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_values = nmf.transform(doc_term_matrix)\n",
    "df['topic'] = topic_values.argmax(axis=1)\n",
    "df['topic_top_10_words'] = top_topic_words\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='topic_top_10_words').rename(columns={'index': 'author_id', 'topic': 'topic_id'}).set_index('author_id').to_csv('texts_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['topic','topic_top_10_words'])[['index']].count().reset_index().rename(columns={'topic': 'topic_id', 'index': 'total_count'}).set_index('topic_id').to_csv('topic_top_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.options.display.width = 0\n",
    "topics = pd.read_csv('topic_top_words.csv', index_col='topic_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_top_10_words</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gedanke|scheinen|moment|sprechen|brief|schreib...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>freundin|wohnung|lieben|kind|erzählen|eigentli...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gras|wald|strand|sand|fisch|meer|himmel|dorf|h...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>schritt|körper|licht|fenster|schauen|wohnung|b...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eltern|sterben|bett|essen|vater|schwester|tant...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rufe|tür|mädchen|affe|beckmann|beobachter|feue...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sterben|schule|sohn|erzählen|wald|baum|hase|gr...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schlielich|wei|whrend|zurck|knnen|wre|wrde|htt...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>erde|dachboden|galizien|scheune|großmutter|sar...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>horizont|karte|findling|kind|strand|vierunddre...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sohn|scheune|balken|tenne|leiter|alte|zwischen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brücke|angler|köder|schwester|zehner|fluß|urft...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>knäckebrot|alleine|augen|holz|esche|sand|hund|...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sass|herrn|schule|res|herr|liess|vater|weiss|b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>phantasmas|divers|zumal|schnee|ihrerseits|näml...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         topic_top_10_words  total_count\n",
       "topic_id                                                                \n",
       "3         gedanke|scheinen|moment|sprechen|brief|schreib...           76\n",
       "10        freundin|wohnung|lieben|kind|erzählen|eigentli...           54\n",
       "11        gras|wald|strand|sand|fisch|meer|himmel|dorf|h...           52\n",
       "0         schritt|körper|licht|fenster|schauen|wohnung|b...           45\n",
       "1         eltern|sterben|bett|essen|vater|schwester|tant...           32\n",
       "9         rufe|tür|mädchen|affe|beckmann|beobachter|feue...           16\n",
       "4         sterben|schule|sohn|erzählen|wald|baum|hase|gr...           15\n",
       "2         schlielich|wei|whrend|zurck|knnen|wre|wrde|htt...           14\n",
       "12        erde|dachboden|galizien|scheune|großmutter|sar...           10\n",
       "14        horizont|karte|findling|kind|strand|vierunddre...            5\n",
       "5         sohn|scheune|balken|tenne|leiter|alte|zwischen...            3\n",
       "6         brücke|angler|köder|schwester|zehner|fluß|urft...            3\n",
       "8         knäckebrot|alleine|augen|holz|esche|sand|hund|...            3\n",
       "13        sass|herrn|schule|res|herr|liess|vater|weiss|b...            3\n",
       "7         phantasmas|divers|zumal|schnee|ihrerseits|näml...            2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.sort_values('total_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
